{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: Defining Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Plotting\n",
    "from matplotlib import pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Auto ARIMA\n",
    "try:\n",
    "    from pmdarima.arima import auto_arima\n",
    "except:\n",
    "    ! pip install pmdarima\n",
    "    from pmdarima.arima import auto_arima\n",
    "\n",
    "class Model(object):\n",
    "    \n",
    "    def __init__(self, test_size=48, predict_size=60):\n",
    "        self.model_dictionary = {}\n",
    "        self.test_size = test_size\n",
    "        self.predict_size = predict_size\n",
    "        \n",
    "    def build_model(self):\n",
    "        zip_codes = self.model_dictionary.keys()\n",
    "        N = len(zip_codes)\n",
    "        for ind, zip_code in enumerate(zip_codes):\n",
    "            self.select_model(zip_code, trace=False)\n",
    "            self.predict_in_sample(zip_code)\n",
    "            self.predict(zip_code)\n",
    "            print(f'Finished processing {ind+1} out of {N}, zip codes.')\n",
    "    \n",
    "    # Load data from data frame\n",
    "    def load_data(self, df):\n",
    "        self.make_datetime_index(df)\n",
    "        for ind in df.index.values:\n",
    "            row = df.loc[ind]\n",
    "            zip_code = self.get_zip_code(row)\n",
    "            row_dict = self.make_row_dict(row)\n",
    "            self.model_dictionary[zip_code] = row_dict\n",
    "    \n",
    "    def make_datetime_index(self, df):\n",
    "        string_index = df.columns.values[8:]\n",
    "        self.datetime_index = pd.to_datetime(string_index)\n",
    "            \n",
    "    def get_zip_code(self, row):\n",
    "        return row['RegionName']\n",
    "            \n",
    "    def make_row_dict(self, row):\n",
    "        row_dict = row.iloc[1:8].to_dict()\n",
    "        time_series = row.iloc[8:]\n",
    "        df = self.make_time_series_df(time_series)\n",
    "        df = df.fillna(df.bfill())\n",
    "        row_dict['TimeSeries'] = df\n",
    "        return row_dict\n",
    "      \n",
    "    def make_time_series_df(self, time_series):\n",
    "        time_series.index = self.datetime_index\n",
    "        df = pd.DataFrame(time_series)\n",
    "        df.columns = ['MedianSales']\n",
    "        return df\n",
    "    \n",
    "    def get_time_series(self, zip_code):\n",
    "        return self.model_dictionary[zip_code]['TimeSeries']\n",
    "    \n",
    "    def get_city_name(self, zip_code):\n",
    "        return self.model_dictionary[zip_code]['City']\n",
    "    \n",
    "    def get_state_abbreviation(self, zip_code):\n",
    "        return self.model_dictionary[zip_code]['State']\n",
    "    \n",
    "    # Train Test Split    \n",
    "    def make_train_test_split(self, zip_code):\n",
    "        time_series_df = self.get_time_series(zip_code)\n",
    "        train = time_series_df[:-self.test_size]\n",
    "        test = time_series_df[-self.test_size:]\n",
    "        return train, test\n",
    "    \n",
    "    # Plotting\n",
    "    def make_time_series_plot(self, zip_code, plot_in_sample_prediction=True, prediction=True):\n",
    "        train, test = self.make_train_test_split(zip_code)\n",
    "        city_name = self.get_city_name(zip_code)\n",
    "        state_abbreviation = self.get_state_abbreviation(zip_code)\n",
    "        fig, ax = plt.subplots(figsize=(8, 5));\n",
    "        ax.plot(train);\n",
    "        ax.plot(test);\n",
    "        legend_labels = ['Train', 'Test']\n",
    "        try:\n",
    "            in_sample_prediction = self.get_in_sample_prediction(zip_code)\n",
    "            ax.plot(in_sample_prediction)\n",
    "            legend_labels.append('Prediction')\n",
    "        except:\n",
    "            pass\n",
    "        ax.legend(legend_labels);\n",
    "        ax.set_title(f'Median Sale Price {city_name}, {state_abbreviation} {zip_code}')\n",
    "        ax.set_xlabel('Date')\n",
    "        ax.set_ylabel('Price')\n",
    "        return fig\n",
    "    \n",
    "    def make_acf_plot(self, zip_code):\n",
    "        city_name = self.get_city_name(zip_code)\n",
    "        state_abbreviation = self.get_state_abbreviation(zip_code)\n",
    "        train, test = self.make_train_test_split(zip_code)\n",
    "        fig, ax = plt.subplots(figsize=(8,5));\n",
    "        plot_acf(\n",
    "            x=train, \n",
    "            ax=ax, \n",
    "            lags=100,\n",
    "            title=f'Autocorrelation for {city_name}, {state_abbreviation} {zip_code}'\n",
    "        );\n",
    "        return fig\n",
    "    \n",
    "    def make_pacf_plot(self, zip_code):\n",
    "        city_name = self.get_city_name(zip_code)\n",
    "        state_abbreviation = self.get_state_abbreviation(zip_code)\n",
    "        train, test = self.make_train_test_split(zip_code)\n",
    "        fig, ax = plt.subplots(figsize=(8,5));\n",
    "        plot_pacf(\n",
    "            x=train, \n",
    "            ax=ax, \n",
    "            lags=100,\n",
    "            title=f'Partial Autocorrelation for {city_name}, {state_abbreviation} {zip_code}'\n",
    "        );\n",
    "        return fig\n",
    "    \n",
    "    # Model Selection\n",
    "    def select_model(self, zip_code, trace=True):\n",
    "        y = self.get_time_series(zip_code)\n",
    "        model = auto_arima(\n",
    "            y = y,\n",
    "            X=None,\n",
    "            start_p=0,\n",
    "            d=1,\n",
    "            start_q=0,\n",
    "            max_p=2,\n",
    "            max_d=2,\n",
    "            max_q=2,\n",
    "            start_P=0,\n",
    "            D=1,\n",
    "            start_Q=0,\n",
    "            max_P=2,\n",
    "            max_D=2,\n",
    "            max_Q=2,\n",
    "            max_order=None,\n",
    "            m=12,\n",
    "            seasonal=True,\n",
    "            stationary=False,\n",
    "            information_criterion='oob',\n",
    "            alpha=0.05,\n",
    "            test='kpss',\n",
    "            seasonal_test='OCSB',\n",
    "            stepwise=True,            \n",
    "            suppress_warnings=True,\n",
    "            error_action='warn',\n",
    "            trace=trace,\n",
    "            out_of_sample_size= self.test_size,\n",
    "            scoring='mse'\n",
    "        )\n",
    "        self.model_dictionary[zip_code]['BestModel'] = model\n",
    "    \n",
    "    def get_best_model(self, zip_code):\n",
    "        try:\n",
    "            best_model = self.model_dictionary[zip_code]['BestModel']\n",
    "        except:\n",
    "            self.select_model(zip_code)\n",
    "            best_model = self.model_dictionary[zip_code]['BestModel']\n",
    "        return best_model\n",
    "    \n",
    "    # Model Validation\n",
    "    def predict_in_sample(self, zip_code):\n",
    "        model = self.get_best_model(zip_code)\n",
    "        time_series = self.get_time_series(zip_code)\n",
    "        index = time_series.index\n",
    "        in_sample_prediction = model.predict_in_sample()\n",
    "        in_sample_prediction_df = pd.DataFrame(in_sample_prediction, index=index)\n",
    "        in_sample_prediction_df.columns = ['MedianSales']\n",
    "        self.model_dictionary[zip_code]['InSamplePrediction'] = in_sample_prediction_df\n",
    "            \n",
    "    def get_in_sample_prediction(self, zip_code):\n",
    "        in_sample_prediction = self.model_dictionary[zip_code]['InSamplePrediction']\n",
    "        return in_sample_prediction\n",
    "    \n",
    "    def plot_diagnostics(self, zip_code):\n",
    "        best_model = self.get_best_model(zip_code)\n",
    "        city = self.get_city_name(zip_code)\n",
    "        state = self.get_state_abbreviation(zip_code)\n",
    "        fig = best_model.plot_diagnostics(figsize=(16, 10));\n",
    "        fig.suptitle(f'Diagnostics for {city}, {state} {zip_code}', fontsize=16)\n",
    "        return fig\n",
    "    \n",
    "    # Predict future prices\n",
    "    def predict(self, zip_code):\n",
    "        model = self.get_best_model(zip_code)\n",
    "        prediction = model.predict(n_periods=self.predict_size)\n",
    "        self.model_dictionary[zip_code]['Prediction'] = prediction\n",
    "        \n",
    "    def get_prediction(self, zip_code):\n",
    "        prediction = self.model_dictionary[zip_code]['Prediction']\n",
    "        return prediction\n",
    "    \n",
    "    # Compute ROI\n",
    "    def compute_roi(self, zip_code):\n",
    "        initial_price = self.get_time_series(zip_code)['MedianSales'][-1]\n",
    "        final_price = self.get_prediction(zip_code)[-1]\n",
    "        roi = (final_price-initial_price)/initial_price\n",
    "        self.model_dictionary[zip_code]['ROI'] = roi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Import the Data\n",
    "Our main data set is stored in the `zillow_data.csv` spreadsheet. We load the CSV file as a data frame below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/ZHVI.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-55550e5e3ca3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/ZHVI.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'RegionID'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/flatiron/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/flatiron/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/flatiron/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    934\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/flatiron/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1169\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/flatiron/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1996\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1998\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1999\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/ZHVI.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/ZHVI.csv', index_col='RegionID')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will restrict our attention to the city of Baltimore, so we filter the data below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.query(\"City == 'Baltimore' and State == 'MD'\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Instantiate the Model and Load in the Data\n",
    "Below we instantiate a Model object and load our selected data into the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model.load_data(df)\n",
    "model.build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: EDA and Visualization\n",
    "Below we display a time series plot, ACF plot, and PACF plot for the zip code 21215. The class methods used below will work for any zip code in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.make_time_series_plot(21215);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.make_acf_plot(21215);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.make_pacf_plot(21215);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: ARIMA Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Interpreting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.make_time_series_plot(21215);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compute_roi(21215)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_diagnostics(21215);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(model.model_dictionary, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
